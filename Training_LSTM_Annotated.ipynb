{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d59532",
   "metadata": {},
   "source": [
    "\n",
    "## üîß ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô CSV ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ\n",
    "\n",
    "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)  \n",
    "‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Notebook:\n",
    "\n",
    "1. **Cell ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (read_csv)**  \n",
    "   - ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ (`pd.read_csv(\"‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà.csv\")`)\n",
    "   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ ‡πÄ‡∏ä‡πà‡∏ô `Close`, `Open`, `Date` ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà  \n",
    "     ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ `data['Close']` ‡∏´‡∏£‡∏∑‡∏≠ `data[['Open', 'Close']]`\n",
    "\n",
    "2. **Cell ‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preprocessing)**  \n",
    "   - ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î `feature_columns`  \n",
    "   - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `Date` ‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ `pd.to_datetime()`\n",
    "\n",
    "3. **Cell ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Building)**  \n",
    "   - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ ‡∏´‡∏≤‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤ shape ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô feature ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î)  \n",
    "     ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á `input_shape` ‡πÉ‡∏ô layer ‡πÅ‡∏£‡∏Å ‡πÄ‡∏ä‡πà‡∏ô `input_shape=(time_steps, num_features)`\n",
    "\n",
    "4. **Cell ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Training)**  \n",
    "   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• `X_train`, `y_train` ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô (‡πÉ‡∏ä‡πâ `.shape` ‡πÄ‡∏ä‡πá‡∏Ñ‡πÑ‡∏î‡πâ)\n",
    "   - ‡∏´‡∏≤‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (`MinMaxScaler`) ‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "\n",
    "5. **Cell ‡∏ó‡∏µ‡πà‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Visualization)**  \n",
    "   - ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏™‡πà‡∏ß‡∏ô `plt.plot(data['Close'])` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "> üí° ‡∏™‡∏£‡∏∏‡∏õ: ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô CSV ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô feature, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15098dea-9bdc-4a56-918e-3325abc910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import joblib\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "for dirname, _, filenames in os.walk('datasets/northSulawesi/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏™‡πÄ‡∏Å‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô feature ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ input_shape=(time_steps, num_features) ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fc4ae-b5af-42d3-9587-84f9d2399b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FILE = 'datasets/northSulawesi/cabai_complete.csv'  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "df = pd.read_csv(FILE, parse_dates=['date'] if 'date' in pd.read_csv(FILE, nrows=0).columns else None)\n",
    "\n",
    "# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\n",
    "if 'date' in df.columns:\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumn & Type:\")\n",
    "print(df.dtypes)\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ ‡πÄ‡∏ä‡πà‡∏ô pd.read_csv('new_data.csv')\n",
    "# üî∏ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏ä‡πà‡∏ô 'Close', 'Open') ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdbc1c-ccfd-46b1-b6cc-dd96eeab675f",
   "metadata": {},
   "source": [
    "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á Exploratory Data Analysis (EDA)\n",
    "- ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏£‡∏∏‡∏õ\n",
    "- ‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226dfb4-4e20-4778-86f6-85715c0f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe(include='all').T)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Visual: price trend (if there is a 'prices' column)\n",
    "# ‡∏†‡∏≤‡∏û: ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏£‡∏≤‡∏Ñ‡∏≤')\n",
    "if 'prices' in df.columns:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(df['prices'])\n",
    "    plt.title(\"Price Trends (prices)\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô CSV ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô plt.plot(...) ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1135c24-73a2-43dc-889e-873da2715f57",
   "metadata": {},
   "source": [
    "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤, ‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô) ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏•‡∏î‡∏Ñ‡πà‡∏≤ NaN\n",
    "‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:\n",
    "- ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏ö‡∏ö‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ min_periods=1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡πà‡∏≤ NaN ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
    "- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô; ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ NaN ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á (‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)\n",
    "- ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (cpi, usd_idr, ‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®) ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ ffill->bfill\n",
    "- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå (‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad749587-c3ad-4e3c-aff4-d5b9a38da4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure prices are there\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "if 'prices' not in df.columns:\n",
    "    raise ValueError(\"Data does not contain a 'prices' column ‚Äî adjust the column names.\")\n",
    "\n",
    "# Copy working df (so as not to modify the original)\n",
    "d = df.copy()\n",
    "\n",
    "# Fill in missing data for exogenous data with forward fill and then back fill (assuming the missing data is small and time series in nature)\n",
    "exo_cols = [c for c in ['cpi', 'usd_idr', 'Temperature', 'Curah Hujan', 'Kelembapan'] if c in d.columns]\n",
    "if exo_cols:\n",
    "    d[exo_cols] = d[exo_cols].ffill().bfill()\n",
    "\n",
    "# Rolling means ‚Äî use min_periods=1 so that early rows have a value\n",
    "d['rolling_mean_7'] = d['prices'].rolling(window=7, min_periods=1).mean()\n",
    "d['rolling_mean_30'] = d['prices'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "# Lag features\n",
    "d['lag_1'] = d['prices'].shift(1)\n",
    "d['lag_7'] = d['prices'].shift(7)\n",
    "d['lag_30'] = d['prices'].shift(30)\n",
    "\n",
    "# NaN filling strategy for lag: fill initial NaNs with current price values (conservative)\n",
    "# Rationale: on the first day there is no history, it is safer to assume the historical value = the price of that day\n",
    "d['lag_1'] = d['lag_1'].fillna(d['prices'])\n",
    "d['lag_7'] = d['lag_7'].fillna(d['prices'])\n",
    "d['lag_30'] = d['lag_30'].fillna(d['prices'])\n",
    "\n",
    "# Delta / pct change\n",
    "d['pct_change_1'] = d['prices'].pct_change().fillna(0)\n",
    "d['pct_change_7'] = d['prices'].pct_change(periods=7).fillna(0)\n",
    "\n",
    "# day features\n",
    "if 'date' in d.columns:\n",
    "    d['weekday'] = d['date'].dt.dayofweek  # 0=Mon..6=Sun\n",
    "    d['day_in_month'] = d['date'].dt.day\n",
    "    d['month'] = d['date'].dt.month\n",
    "else: \n",
    "    # if there is no date, try using the day_in_month column if available\n",
    "    if 'day_in_month' not in d.columns:\n",
    "        d['day_in_month'] = 0\n",
    "\n",
    "# Check results\n",
    "display(d.head(10))\n",
    "print(\"\\nMissing after imputation (should be 0 for features used):\")\n",
    "print(d[['rolling_mean_7','rolling_mean_30','lag_1','lag_7','lag_30','pct_change_1']].isna().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f808fe80-7057-48f4-b300-ff5842545a56",
   "metadata": {},
   "source": [
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏ß‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)\n",
    "- ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e83424-7223-4220-9f79-539f38f44c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'prices', 'rolling_mean_7', 'rolling_mean_30', 'lag_1', 'lag_7', 'lag_30',\n",
    "    'pct_change_1', 'pct_change_7', 'weekday', 'day_in_month'\n",
    "]\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
    "for ex in exo_cols:\n",
    "    features.append(ex)\n",
    "\n",
    "# ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà\n",
    "missing = [c for c in features if c not in d.columns]\n",
    "if missing:\n",
    "    raise ValueError(\"Kolom hilang: \" + \", \".join(missing))\n",
    "\n",
    "df_feat = d[features].copy()\n",
    "display(df_feat.head())\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_feat.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation (final features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ff69a-dcae-48ef-9d45-8cd53726f5a6",
   "metadata": {},
   "source": [
    "‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡πà‡∏ß‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•) (data leakage)\n",
    "- ‡πÉ‡∏ä‡πâ window_size = 30\n",
    "- ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "- ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652f381-1b7f-4719-954d-0f955a662406",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values = df_feat.values  # shape (n_rows, n_features)\n",
    "n_rows, n_features = raw_values.shape\n",
    "window_size = 30\n",
    "\n",
    "# Count sequences available\n",
    "seq_count = n_rows - window_size\n",
    "if seq_count <= 0:\n",
    "    raise ValueError(\"Data tidak cukup untuk window_size yang dipilih\")\n",
    "\n",
    "# Training sequences count (time-based split)\n",
    "train_seq_count = int(seq_count * 0.8)\n",
    "rows_for_scaler = train_seq_count + window_size  # rows needed to construct training windows\n",
    "print(f\"n_rows={n_rows}, seq_count={seq_count}, train_seq_count={train_seq_count}, rows_for_scaler={rows_for_scaler}\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(raw_values[:rows_for_scaler, :])  # fit only on training rows (prevent leakage)\n",
    "\n",
    "scaled_all = scaler.transform(raw_values)     # transform all rows for convenience\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences_from_scaled(scaled_array, window):\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_array) - window):\n",
    "        X.append(scaled_array[i:i+window])\n",
    "        y.append(scaled_array[i+window, 0])  # target: kolom 'prices' (index 0)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences_from_scaled(scaled_all, window_size)\n",
    "print(\"Total sequences:\", X.shape, y.shape)\n",
    "\n",
    "# Split\n",
    "X_train, X_test = X[:train_seq_count], X[train_seq_count:]\n",
    "y_train, y_test = y[:train_seq_count], y[train_seq_count:]\n",
    "print(\"Shapes -> X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏™‡πÄ‡∏Å‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802d363-8f39-4c49-82a9-7357c98a4d1b",
   "metadata": {},
   "source": [
    "Model architecture: LSTM_v2_Imputed\n",
    "Architecture:\n",
    "- LSTM(128, return_sequences=True)\n",
    "- Dropout(0.3)\n",
    "- LSTM(64)\n",
    "- Dropout(0.3)\n",
    "- Dense(64, relu)\n",
    "- Dense(1)\n",
    "\n",
    "Rationale:\n",
    "- Two LSTM layers help the model capture complex temporal patterns\n",
    "- Dropout for regularization\n",
    "- Dense layers help with non-linear mapping before output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eee08d-0d03-43ce-8adc-ef6a956891b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô feature ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ input_shape=(time_steps, num_features) ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f774e4-4e5c-4434-91d3-66db9baf4cea",
   "metadata": {},
   "source": [
    "Training\n",
    "- EarlyStopping: stop if val_loss doesn't improve\n",
    "- ReduceLROnPlateau: reduce LR if it plateaus\n",
    "- ModelCheckpoint: save the best model\n",
    "- Goal: optimize the model while avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad6357-99c0-493f-8f55-365491d3aa82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "ckpt_path = \"models/LSTM_v2_Imputed_best.h5\"\n",
    "mc = ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es, rlr, mc],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754bdc4-6b82-49fd-aeac-cbb3c805a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load best model & evaluation\n",
    "- Muat model terbaik dari checkpoint\n",
    "- Prediksi X_test (scaled)\n",
    "- Inverse transform predictions & actual ke skala asli\n",
    "- Hitung MSE, MAE, RMSE\n",
    "\"\"\"\n",
    "if os.path.exists(ckpt_path):\n",
    "    model = load_model(ckpt_path)\n",
    "\n",
    "# Predict (scaled)\n",
    "pred_scaled = model.predict(X_test)\n",
    "\n",
    "# inverse transform helper\n",
    "def inv_transform_target(scaled_target_array, scaler, n_features):\n",
    "    \"\"\"\n",
    "    Inverse transform helper to return prices to their original scale.\n",
    "    scaled_target_array: an (N,) or (N,1) array containing the scaled targets (column 0)\n",
    "    scaler: the fitted scaler\n",
    "    n_features: the total number of features\n",
    "    \"\"\"\n",
    "    scaled_target_array = scaled_target_array.flatten()  # pastikan bentuk (N,)\n",
    "    dummy = np.zeros((len(scaled_target_array), n_features))\n",
    "    dummy[:, 0] = scaled_target_array\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "y_test_inv = inv_transform_target(y_test, scaler, n_features)\n",
    "pred_inv = inv_transform_target(pred_scaled, scaler, n_features)\n",
    "\n",
    "mse = mean_squared_error(y_test_inv, pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, pred_inv)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b75486-aa56-4b64-bce8-19fe553c4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualisasi:\n",
    "- Actual vs Predicted\n",
    "- Error distribution\n",
    "- Training/validation loss\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(y_test_inv, label='Actual', color='blue')\n",
    "plt.plot(pred_inv, label='Predicted', color='orange')\n",
    "plt.title(\"Actual vs Predicted (Test Set)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Error distribution\n",
    "errors = y_test_inv - pred_inv\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(errors, bins=40, kde=True)\n",
    "plt.title(\"Error distribution (Actual - Predicted)\")\n",
    "plt.show()\n",
    "\n",
    "# Loss curves\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.show()\n",
    "# üî∏ ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô CSV ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô plt.plot(...) ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a1978-593b-40f7-a606-92dd8a071ea5",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Save model & scaler\n",
    "- Save LSTM_v2_Imputed model and scaler\n",
    "- Log simple metadata (version, date)\n",
    "\n",
    "MODEL_OUT = \"/kaggle/working/LSTM_v2_Imputed.h5\"\n",
    "SCALER_OUT = \"/kaggle/working/price_scaler_v2.save\"\n",
    "model.save(MODEL_OUT)\n",
    "joblib.dump(scaler, SCALER_OUT)\n",
    "\n",
    "# Write metadata\n",
    "meta = {\n",
    "    \"model_name\": \"LSTM_v2_Imputed\",\n",
    "    \"window_size\": window_size,\n",
    "    \"features\": features,\n",
    "    \"n_features\": n_features\n",
    "}\n",
    "import json\n",
    "with open(\"/kaggle/working/LSTM_v2_Imputed_metadata.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(\"Saved model, scaler, and metadata.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299443f-7bbe-472d-abc0-24b45a5f3a89",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "Function predict_next_day\n",
    "- Input: model, scaler, raw_values ‚Äã‚Äã(original features in original scale), window_size\n",
    "- Output: predicted price (original scale)\n",
    "- Note: make sure the final raw_values ‚Äã‚Äãhave the features we have defined\n",
    "\n",
    "def predict_next_day(model, scaler, raw_values_array, window_size=30):\n",
    "    # raw_values_array: ndarray (n_rows, n_features) in original scale (same order as 'features')\n",
    "    last_window_raw = raw_values_array[-window_size:, :]\n",
    "    last_window_scaled = scaler.transform(last_window_raw)\n",
    "    X_input = last_window_scaled.reshape(1, window_size, last_window_scaled.shape[1])\n",
    "    pred_scaled = model.predict(X_input)\n",
    "    # inverse transform prediction\n",
    "    dummy = np.zeros((1, n_features))\n",
    "    dummy[0,0] = pred_scaled.flatten()[0]\n",
    "    pred_inv = scaler.inverse_transform(dummy)[0,0]\n",
    "    return float(pred_inv)\n",
    "\n",
    "# usage example (raw_values ‚Äã‚Äãis df_feat.values ‚Äã‚Äãfrom Cell 5)\n",
    "pred_next = predict_next_day(model, scaler, df_feat.values, window_size=window_size)\n",
    "print(\"Tomorrow's price prediction (1-step):\", pred_next)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c4add-2a81-49c7-b7c8-1abd823a4eae",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Simulasi update harian:\n",
    "- Simulasikan admin memasukkan harga hari ini\n",
    "- Bangun baris baru dengan fitur (disederhanakan: gunakan last row untuk exogenous)\n",
    "- Append ke raw_values (tidak overwrite file asli) lalu panggil predict_next_day\n",
    "\n",
    "# contoh: input manual\n",
    "harga_hari_ini = float(input(\"Masukkan harga hari ini (simulasi): \"))\n",
    "\n",
    "# gunakan row terakhir sebagai basis fitur\n",
    "last_row_raw = raw_values[-1].copy()  # raw_values diambil dari Cell 6 awal (df_feat.values)\n",
    "new_row = last_row_raw.copy()\n",
    "new_row[0] = harga_hari_ini\n",
    "\n",
    "# update rolling & lag di new_row: (opsional, sederhana)\n",
    "# lebih baik compute new_row fitur sebenarnya via helper fungsi yang memakai history + sumber exogenous\n",
    "raw_values_upd = np.vstack([raw_values, new_row])\n",
    "\n",
    "pred_after_input = predict_next_day(model, scaler, raw_values_upd, window_size)\n",
    "print(\"Prediksi harga besok setelah input harga terbaru:\", pred_after_input)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9d5cca5-ceca-4d2b-a8b1-471353fd607c",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"guide-intro\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CSV ‡πÉ‡∏´‡∏°‡πà\\n\",\n",
    "    \"\\n\",\n",
    "    \"## ‚ö†Ô∏è ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô CSV\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 1. **Cell ‡∏ó‡∏µ‡πà 2** - ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `FILE` ‡πÉ‡∏´‡πâ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡πÉ‡∏´‡∏°‡πà\\n\",\n",
    "    \"- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `date` ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∞‡πÉ‡∏ä‡πâ index ‡πÅ‡∏ó‡∏ô)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 2. **Cell ‡∏ó‡∏µ‡πà 3** - ‡∏î‡∏π Structure ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ** - ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏ö‡πâ‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡∏°‡∏µ missing values ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 3. **Cell ‡∏ó‡∏µ‡πà 5** - Feature Engineering ‚≠ê **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**\\n\",\n",
    "    \"- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ CSV ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `prices` (‡∏£‡∏≤‡∏Ñ‡∏≤) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà - **‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô**\\n\",\n",
    "    \"- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå exogenous variables:\\n\",\n",
    "    \"  - `cpi` (‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ)\\n\",\n",
    "    \"  - `usd_idr` (‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)\\n\",\n",
    "    \"  - `Temperature` (‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥)\\n\",\n",
    "    \"  - `Curah Hujan` (‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ù‡∏ô)\\n\",\n",
    "    \"  - `Kelembapan` (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô)\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤ CSV ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ** - ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å `exo_cols`\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°** - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô `exo_cols`\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 4. **Cell ‡∏ó‡∏µ‡πà 6** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Features ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‚≠ê **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**\\n\",\n",
    "    \"- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç list `features` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"- Feature engineering ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (rolling_mean, lag, pct_change) ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô Cell 5\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ weekday/day_in_month** - ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å list\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 5. **Cell ‡∏ó‡∏µ‡πà 7** - ‡∏™‡∏£‡πâ‡∏≤‡∏á Sequences\\n\",\n",
    "    \"- ‡πÅ‡∏Å‡πâ `window_size` ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß time window (default = 30)\\n\",\n",
    "    \"- ‡πÅ‡∏Å‡πâ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô train/test ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `0.8` ‡πÉ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î train_seq_count\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 6. **Cell ‡∏ó‡∏µ‡πà 8-10** - Model & Training\\n\",\n",
    "    \"- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ** - ‡πÅ‡∏ï‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö hyperparameters ‡πÑ‡∏î‡πâ:\\n\",\n",
    "    \"  - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô LSTM units (128, 64)\\n\",\n",
    "    \"  - Dropout rate (0.3)\\n\",\n",
    "    \"  - Learning rate, batch_size, epochs\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 7. **Cell ‡∏ó‡∏µ‡πà 11-12** - Evaluation & Visualization\\n\",\n",
    "    \"- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ** - ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## üìã Checklist ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô\\n\",\n",
    "    \"- [ ] ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Cell 2\\n\",\n",
    "    \"- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `prices` (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠)\\n\",\n",
    "    \"- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå exogenous ‡πÉ‡∏ô Cell 5\\n\",\n",
    "    \"- [ ] ‡∏õ‡∏£‡∏±‡∏ö list `features` ‡πÉ‡∏ô Cell 6\\n\",\n",
    "    \"- [ ] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ window_size ‡πÅ‡∏•‡∏∞ train/test split ‡πÉ‡∏ô Cell 7\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"15098dea-9bdc-4a56-918e-3325abc910ed\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 1: Import libraries\\n\",\n",
    "    \"# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\\n\",\n",
    "    \"\\n\",\n",
    "    \"import os, random\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.preprocessing import MinMaxScaler\\n\",\n",
    "    \"from sklearn.metrics import mean_squared_error, mean_absolute_error\\n\",\n",
    "    \"\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras.models import Sequential, load_model\\n\",\n",
    "    \"from tensorflow.keras.layers import LSTM, Dense, Dropout\\n\",\n",
    "    \"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\\n\",\n",
    "    \"\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ seed ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\\n\",\n",
    "    \"SEED = 42\\n\",\n",
    "    \"np.random.seed(SEED)\\n\",\n",
    "    \"random.seed(SEED)\\n\",\n",
    "    \"tf.random.set_seed(SEED)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\\n\",\n",
    "    \"for dirname, _, filenames in os.walk('datasets/northSulawesi/'):\\n\",\n",
    "    \"    for filename in filenames:\\n\",\n",
    "    \"        print(os.path.join(dirname, filename))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"load-data-guide\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß Cell 2: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - **‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô CSV**\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:\\n\",\n",
    "    \"1. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `FILE` ‡πÉ‡∏´‡πâ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\\n\",\n",
    "    \"2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `date` ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\\n\",\n",
    "    \"   - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ: ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\\n\",\n",
    "    \"   - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ: ‡∏à‡∏∞‡πÉ‡∏ä‡πâ index ‡∏Ç‡∏≠‡∏á DataFrame ‡πÅ‡∏ó‡∏ô\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"067fc4ae-b5af-42d3-9587-84f9d2399b97\",\n",
    "   \"metadata\": {\n",
    "    \"scrolled\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 2: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå CSV ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\\n\",\n",
    "    \"FILE = 'datasets/northSulawesi/cabai_complete.csv'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\\n\",\n",
    "    \"df = pd.read_csv(FILE, parse_dates=['date'] if 'date' in pd.read_csv(FILE, nrows=0).columns else None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\\n\",\n",
    "    \"if 'date' in df.columns:\\n\",\n",
    "    \"    df = df.sort_values('date').reset_index(drop=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Shape:\\\", df.shape)\\n\",\n",
    "    \"display(df.head())\\n\",\n",
    "    \"print(\\\"\\\\nColumn & Type:\\\")\\n\",\n",
    "    \"print(df.dtypes)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5abdbc1c-ccfd-46b1-b6cc-dd96eeab675f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Cell 3: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á Exploratory Data Analysis (EDA)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ Cell ‡∏ô‡∏µ‡πâ\\n\",\n",
    "    \"- ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏£‡∏∏‡∏õ\\n\",\n",
    "    \"- ‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\\n\",\n",
    "    \"- ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `prices`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"6226dfb4-4e20-4778-86f6-85715c0f233a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (EDA)\\n\",\n",
    "    \"# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\\n\",\n",
    "    \"display(df.describe(include='all').T)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤ missing ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\\n\",\n",
    "    \"print(\\\"\\\\nMissing values per column:\\\")\\n\",\n",
    "    \"print(df.isna().sum())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'prices')\\n\",\n",
    "    \"if 'prices' in df.columns:\\n\",\n",
    "    \"    plt.figure(figsize=(12,4))\\n\",\n",
    "    \"    plt.plot(df['prices'])\\n\",\n",
    "    \"    plt.title(\\\"Price Trends (prices)\\\")\\n\",\n",
    "    \"    plt.ylabel(\\\"Price\\\")\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"feature-engineering-guide\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß Cell 5: Feature Engineering - **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ**\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 1. ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤ (Target Variable)\\n\",\n",
    "    \"- ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `prices` ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ** (‡πÄ‡∏ä‡πà‡∏ô `price`, `harga`, `Price`) ‚Üí ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ:\\n\",\n",
    "    \"  ```python\\n\",\n",
    "    \"  if '‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì' not in df.columns:\\n\",\n",
    "    \"  ```\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 2. Exogenous Variables (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å)\\n\",\n",
    "    \"- ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ: `cpi`, `usd_idr`, `Temperature`, `Curah Hujan`, `Kelembapan`\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤ CSV ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ** ‚Üí ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å list `exo_cols`\\n\",\n",
    "    \"- **‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°** (‡πÄ‡∏ä‡πà‡∏ô `humidity`, `rainfall`) ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô list\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 3. ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\\n\",\n",
    "    \"- ‡∏ñ‡πâ‡∏≤ CSV ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `date` ‚Üí ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á `weekday`, `day_in_month`, `month` ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\\n\",\n",
    "    \"- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí ‡∏à‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ `day_in_month = 0`\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Features ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:\\n\",\n",
    "    \"- `rolling_mean_7` - ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 7 ‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á\\n\",\n",
    "    \"- `rolling_mean_30` - ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 30 ‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á\\n\",\n",
    "    \"- `lag_1`, `lag_7`, `lag_30` - ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 1, 7, 30 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"- `pct_change_1`, `pct_change_7` - % ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ad749587-c3ad-4e3c-aff4-d5b9a38da4bf\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 5: Feature Engineering\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'prices' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\\n\",\n",
    "    \"# ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ ‡πÄ‡∏ä‡πà‡∏ô 'price' ‡∏´‡∏£‡∏∑‡∏≠ 'harga' ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\\n\",\n",
    "    \"if 'prices' not in df.columns:\\n\",\n",
    "    \"    raise ValueError(\\\"Data does not contain a 'prices' column ‚Äì adjust the column names.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å DataFrame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\\n\",\n",
    "    \"d = df.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (exogenous variables)\\n\",\n",
    "    \"# ‡∏ñ‡πâ‡∏≤ CSV ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å\\n\",\n",
    "    \"# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô list\\n\",\n",
    "    \"exo_cols = [c for c in ['cpi', 'usd_idr', 'Temperature', 'Curah Hujan', 'Kelembapan'] if c in d.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ missing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ forward fill ‡πÅ‡∏•‡∏∞ back fill\\n\",\n",
    "    \"if exo_cols:\\n\",\n",
    "    \"    d[exo_cols] = d[exo_cols].ffill().bfill()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á Rolling Means (‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà)\\n\",\n",
    "    \"# ‡πÉ‡∏ä‡πâ min_periods=1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡πÜ ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤\\n\",\n",
    "    \"d['rolling_mean_7'] = d['prices'].rolling(window=7, min_periods=1).mean()\\n\",\n",
    "    \"d['rolling_mean_30'] = d['prices'].rolling(window=30, min_periods=1).mean()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á Lag Features (‡∏£‡∏≤‡∏Ñ‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á)\\n\",\n",
    "    \"d['lag_1'] = d['prices'].shift(1)\\n\",\n",
    "    \"d['lag_7'] = d['prices'].shift(7)\\n\",\n",
    "    \"d['lag_30'] = d['prices'].shift(30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ NaN ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡πÜ ‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\\n\",\n",
    "    \"# ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•: ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡∏à‡∏∂‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô\\n\",\n",
    "    \"d['lag_1'] = d['lag_1'].fillna(d['prices'])\\n\",\n",
    "    \"d['lag_7'] = d['lag_7'].fillna(d['prices'])\\n\",\n",
    "    \"d['lag_30'] = d['lag_30'].fillna(d['prices'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á Percentage Change (% ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)\\n\",\n",
    "    \"d['pct_change_1'] = d['prices'].pct_change().fillna(0)\\n\",\n",
    "    \"d['pct_change_7'] = d['prices'].pct_change(periods=7).fillna(0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á Time Features (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date)\\n\",\n",
    "    \"if 'date' in d.columns:\\n\",\n",
    "    \"    d['weekday'] = d['date'].dt.dayofweek  # 0=‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå..6=‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå\\n\",\n",
    "    \"    d['day_in_month'] = d['date'].dt.day\\n\",\n",
    "    \"    d['month'] = d['date'].dt.month\\n\",\n",
    "    \"else: \\n\",\n",
    "    \"    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ date ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå day_in_month ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\\n\",\n",
    "    \"    if 'day_in_month' not in d.columns:\\n\",\n",
    "    \"        d['day_in_month'] = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\\n\",\n",
    "    \"display(d.head(10))\\n\",\n",
    "    \"print(\\\"\\\\nMissing values after imputation (‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ):\\\")\\n\",\n",
    "    \"print(d[['rolling_mean_7','rolling_mean_30','lag_1','lag_7','lag_30','pct_change_1']].isna().sum())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"feature-selection-guide\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß Cell 6: ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Features ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - **‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ**\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:\\n\",\n",
    "    \"1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö list `features` ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\\n\",\n",
    "    \"2. **Features ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö:**\\n\",\n",
    "    \"   - `prices` - ‡∏£‡∏≤‡∏Ñ‡∏≤ (target)\\n\",\n",
    "    \"   - Features ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å Cell 5: `rolling_mean_7`, `rolling_mean_30`, `lag_1`, `lag_7`, `lag_30`, `pct_change_1`, `pct_change_7`\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Features ‡πÄ‡∏™‡∏£‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å):**\\n\",\n",
    "    \"   - `weekday`, `day_in_month`, `month` (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date)\\n\",\n",
    "    \"   - `cpi`, `usd_idr`, `Temperature`, `Curah Hujan`, `Kelembapan` (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å)\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô Cell 5** ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô list ‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"94e83424-7223-4220-9f79-539f38f44c36\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 6: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Features ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏£‡∏∞‡∏ö‡∏∏ features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\\n\",\n",
    "    \"# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"features = [\\n\",\n",
    "    \"    'prices',           # ‡∏£‡∏≤‡∏Ñ‡∏≤ (target)\\n\",\n",
    "    \"    'rolling_mean_7',   # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 7 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"    'rolling_mean_30',  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 30 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"    'lag_1',           # ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏ô‡∏µ‡πâ\\n\",\n",
    "    \"    'lag_7',           # ‡∏£‡∏≤‡∏Ñ‡∏≤ 7 ‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô\\n\",\n",
    "    \"    'lag_30',          # ‡∏£‡∏≤‡∏Ñ‡∏≤ 30 ‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô\\n\",\n",
    "    \"    'pct_change_1',    # % ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á 1 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"    'pct_change_7',    # % ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á 7 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"    'weekday',         # ‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (0-6)\\n\",\n",
    "    \"    'day_in_month'     # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (1-31)\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (exogenous) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\\n\",\n",
    "    \"for ex in exo_cols:\\n\",\n",
    "    \"    features.append(ex)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\\n\",\n",
    "    \"missing = [c for c in features if c not in d.columns]\\n\",\n",
    "    \"if missing:\\n\",\n",
    "    \"    raise ValueError(\\\"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: \\\" + \\\", \\\".join(missing))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö features ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å\\n\",\n",
    "    \"df_feat = d[features].copy()\\n\",\n",
    "    \"display(df_feat.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÅ‡∏™‡∏î‡∏á Correlation Matrix (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á features)\\n\",\n",
    "    \"plt.figure(figsize=(10,8))\\n\",\n",
    "    \"sns.heatmap(df_feat.corr(), annot=True, fmt=\\\".2f\\\", cmap='coolwarm')\\n\",\n",
    "    \"plt.title(\\\"Correlation (final features)\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"sequence-guide\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß Cell 7: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Sequences ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - **‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ**\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ:\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 1. `window_size` (default = 30)\\n\",\n",
    "    \"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\\n\",\n",
    "    \"- **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** 7-60 ‡∏ß‡∏±‡∏ô\\n\",\n",
    "    \"- ‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏à‡∏≥‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 2. Train/Test Split (default = 80:20)\\n\",\n",
    "    \"- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: `train_seq_count = int(seq_count * 0.8)`\\n\",\n",
    "    \"- **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** 0.7-0.9 (70-90% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡πà‡∏ß‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Leakage)\\n\",\n",
    "    \"- Scaler ‡∏ñ‡∏π‡∏Å fit ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\\n\",\n",
    "    \"- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ normalize\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"3652f381-1b7f-4719-954d-0f955a662406\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cell 7: ‡∏™‡∏£‡πâ‡∏≤‡∏á Sequences ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train/Test\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô numpy array\\n\",\n",
    "    \"raw_values = df_feat.values  # shape (n_rows, n_features)\\n\",\n",
    "    \"n_rows, n_features = raw_values.shape\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏Ç‡∏ô‡∏≤‡∏î window (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢)\\n\",\n",
    "    \"window_size = 30\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô sequences ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ\\n\",\n",
    "    \"seq_count = n_rows - window_size\\n\",\n",
    "    \"if seq_count <= 0:\\n\",\n",
    "    \"    raise ValueError(\\\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö window_size ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô train/test (default = 80% train, 20% test)\\n\",\n",
    "    \"train_seq_count = int(seq_count * 0.8)\\n\",\n",
    "    \"rows_for_scaler = train_seq_count + window_size  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fit scaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"n_rows={n_rows}, seq_count={seq_count}, train_seq_count={train_seq_count}, rows_for_scaler={rows_for_scaler}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ‡∏™‡∏£‡πâ‡∏≤‡∏á Scaler ‡πÅ‡∏•‡∏∞ fit ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô data leakage)\\n\",\n",
    "    \"scaler = MinMaxScaler()\\n\",\n",
    "    \"scaler.fit(raw_values[:rows_for_scaler, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef7bf9-7600-4c18-b439-015a56a590d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
